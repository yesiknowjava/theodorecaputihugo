---
title: "\"Did I say something wrong?\": Responses to addiction help-seeking from Intelligent Virtual Assistants on Alexa, Siri, Google Assistant, Bixby, and Cortana."

authors:
- "Alicia L. Nobles"
- "Eric C. Leas"
- "admin"
- "Shu-Hong Zhu"
- "Steffanie A. Strathdee"
- "John W. Ayers"
date: "2020-01-01T00:00:00Z"
doi: "10.1038/s41746-019-0215-9"
venue: "npj Digital Medicine"
publishDate: "2017-01-01T00:00:00Z"
publication_types: ["2"]
abstract: "We investigated how intelligent virtual assistants (IVA), including Amazonâ€™s Alexa, Appleâ€™s Siri, Google Assistant, Microsoftâ€™s Cortana, and Samsungâ€™s Bixby, responded to addiction help-seeking queries. We recorded if IVAs provided a singular response and if so, did they link users to treatment or treatment referral services. Only 4 of the 70 help-seeking queries presented to the five IVAs returned singular responses, with the remainder prompting confusion (e.g., â€œdid I say something wrong?â€). When asked â€œhelp me quit drugsâ€ Alexa responded with a definition for the word drugs. â€œHelp me quitâ€¦smokingâ€ or â€œtobaccoâ€ on Google Assistant returned Dr. QuitNow (a cessation app), while on Siri â€œhelp me quit potâ€ promoted a marijuana retailer. IVAs should be revised to promote free, remote, federally sponsored addiction services, such as SAMSHAâ€™s 1-800-662-HELP helpline. This would benefit millions of IVA users now and more to come as IVAs displace existing information-seeking engines."
summary: "Nobles, A. L., Leas, E. C., Caputi, T. L., Zhu, S.-H., Strathdee, S. A., & Ayers, J. W. (2020). Responses to addiction help-seeking from Alexa, Siri, Google Assistant, Cortana, and Bixby intelligent virtual assistants. Npj Digital Medicine, 3(1). doi:10.1038/s41746-019-0215-9"
tags: 
featured: false
links:
- name: Paper Link
  url: "https://www.nature.com/articles/s41746-019-0215-9"
url_pdf: "/files/NDM-2020.pdf"
image:
  focal_point: ""
  preview_only: false
---